import os
import copy
import json
import contextlib
import itertools

import synapse.exc as s_exc
import synapse.cortex as s_cortex

import synapse.tests.utils as s_t_utils

import synapse.lib.msgpack as s_msgpack

import synapse.tools.migrate_020 as s_migr

REGR_REPO = '/home/mike/git/synapse-regression'  # TODO hard-coded for testing, replace with utils.getRegrDir
REGR_DIR = '0.1.51-migr'

# Nodes that are expected to be unmigratable
NOMIGR_NDEF = [
    ["migr:test", 22],
    ["test:int", 10],
]

# Error log to be generated by migr:test
# .created val removed since this will update when the regression repo is updated
MIGR_ERR = {
    'migrop': 'nodes',
    'logtyp': 'error',
    'key': b'\xc8ak\x08\xb8\x8fJ\xcd\xad/\xc4F\x08\x7f@\xc9k\xf8\xc4\xca\x807|\xacK\xe5\xff<\x88+7\xef',
    'val': {
        'mesg': "Unable to determine stortype for migr:test: 'NoneType' object has no attribute 'type'",
        'node': (
            b'\xc8ak\x08\xb8\x8fJ\xcd\xad/\xc4F\x08\x7f@\xc9k\xf8\xc4\xca\x807|\xacK\xe5\xff<\x88+7\xef',
            {
                'ndef': ('*migr:test', 22),
                'props': {'bar': 'spam'},
                'tags': {}, 'tagprops': {}
            }
        )
    }
}

def getAssetBytes(*paths):
    fp = os.path.join(*paths)
    assert os.path.isfile(fp)
    with open(fp, 'rb') as f:
        byts = f.read()
    return byts

def getAssetJson(*paths):
    byts = getAssetBytes(*paths)
    obj = json.loads(byts.decode())
    return obj

def convertJsonLists(elm):
    '''
    Recursively convert lists to tuples for equality comparisons.
    '''

    if isinstance(elm, list):
        for i, e in enumerate(elm):
            elm[i] = convertJsonLists(e)

        return tuple(elm)

    elif isinstance(elm, dict):
        for k, v in elm.items():
            elm[k] = convertJsonLists(v)

        return elm

    else:
        return elm

class MigrationTest(s_t_utils.SynTest):

    @contextlib.asynccontextmanager
    async def _getTestMigrCore(self, conf):
        '''
        Use regression cortex as the base migration dirn.

        Args:
            conf (dict): Migration tool configuration

        Yields:
            (list): List of podes in the cortex
            (s_migr.Migrator): Migrator service object
            (tuple): test data, dest dirn, dest local layers, Migrator
        '''
        path_cortex = ('cortexes', REGR_DIR)
        path_assets = ('assets', REGR_DIR)

        regr = os.path.join(REGR_REPO, *path_cortex)
        assets = os.path.join(REGR_REPO, *path_assets)

        # get test data
        tdata = {}
        podesj = getAssetJson(assets, 'podes.json')
        ndj = getAssetJson(assets, 'nodedata.json')

        # strip out data we don't expect to migrate
        podesj = [p for p in podesj if p[0] not in NOMIGR_NDEF]
        ndj = [nd for nd in ndj if nd[0] not in NOMIGR_NDEF]

        tdata['podes'] = convertJsonLists(podesj)
        tdata['nodedata'] = convertJsonLists(ndj)

        # initialize migration tool
        with self.getTestDir(copyfrom=regr) as src:
            with self.getTestDir(copyfrom=conf.get('dest')) as dest:
                tconf = copy.deepcopy(conf)
                tconf['src'] = src
                tconf['dest'] = dest

                locallyrs = os.listdir(os.path.join(src, 'layers'))

                async with await s_migr.Migrator.anit(tconf) as migr:
                    yield tdata, dest, locallyrs, migr

    async def _checkStats(self, tdata, migr, locallyrs):
        '''
        Verify that the stats for what data has been migrated matches the test data
        '''
        tpodes = tdata['podes']
        tnodedata = tdata['nodedata']

        ipv4_cnt = len([x for x in tpodes if x[0][0] == 'inet:ipv4'])
        bytes_cnt = len([x for x in tpodes if x[0][0] == 'file:bytes'])
        tag_cnt = len([x for x in tpodes if x[0][0] == 'syn:tag'])

        nodedata_cnt = sum([len(x[1]) for x in tnodedata])

        ipv4_migr = [0, 0]
        bytes_migr = [0, 0]
        tag_migr = [0, 0]
        totnodes_migr = 0

        totnodedata_migr = 0

        for iden in locallyrs:
            stats = [log async for log in migr._migrlogGet('nodes', 'stat', f'{iden}:form')]
            self.gt(len(stats), 0)
            for stat in stats:
                skey = stat['key']
                sval = stat['val']  # (src_cnt, dest_cnt)

                if skey.endswith('inet:ipv4'):
                    ipv4_migr[0] += sval[0]
                    ipv4_migr[1] += sval[1]
                elif skey.endswith('file:bytes'):
                    bytes_migr[0] += sval[0]
                    bytes_migr[1] += sval[1]
                elif skey.endswith('syn:tag'):
                    tag_migr[0] += sval[0]
                    tag_migr[1] += sval[1]

            totnodes = [log async for log in migr._migrlogGet('nodes', 'stat', f'{iden}:totnodes')]
            totnodes_migr += totnodes[0]['val'][1]  # dest cnt

            totnodedata = [log async for log in migr._migrlogGet('nodedata', 'stat', f'{iden}:totnodes')]
            totnodedata_migr += totnodedata[0]['val'][1]  # dest cnt

        # check that sums from the layer migrations add up
        self.eq((ipv4_cnt, ipv4_cnt), ipv4_migr)
        self.eq((bytes_cnt, bytes_cnt), bytes_migr)
        self.eq((tag_cnt, tag_cnt), tag_migr)
        self.eq(len(tpodes), totnodes_migr)

        self.eq(nodedata_cnt, totnodedata_migr)

    async def _checkCore(self, core, tdata):
        '''
        Verify data in the migrated to 0.2.x cortex.
        '''

        # test validation data
        tpodes = tdata['podes']
        tnodedata = tdata['nodedata']

        # check all nodes
        nodes = await core.nodes('.created -meta:source:name=test')

        podes = [n.pack(dorepr=True) for n in nodes]
        self.gt(len(podes), 0)

        try:
            self.eq(podes, tpodes)
        except AssertionError:
            # print a more useful diff on error
            notincore = list(itertools.filterfalse(lambda x: x in podes, tpodes))
            self.eq([], notincore)
            notintest = list(itertools.filterfalse(lambda x: x in tpodes, podes))
            self.eq([], notintest)
            raise

        nodedata = []
        for n in nodes:
            nodedata.append([n.ndef, [nd async for nd in n.iterData()]])
        nodedata = convertJsonLists(nodedata)
        try:
            self.eq(nodedata, tnodedata)
        except AssertionError:
            # print a more useful diff on error
            notincore = list(itertools.filterfalse(lambda x: x in nodedata, tnodedata))
            self.eq([], notincore)
            notintest = list(itertools.filterfalse(lambda x: x in tnodedata, nodedata))
            self.eq([], notintest)
            raise

        # manually check node subset
        self.len(1, await core.nodes('inet:ipv4=1.2.3.4'))
        self.len(2, await core.nodes('inet:dns:a:ipv4=1.2.3.4'))

        # check that triggers are active
        root = await core.auth.getUserByName('root')
        triggers = await core.view.packTriggers(root.iden)
        self.len(2, triggers)
        self.len(2, await core.eval('syn:trigger').list())
        tnodes = await core.nodes('[ inet:ipv4=9.9.9.9 ]')
        self.nn(tnodes[0].tags.get('trgtag'))

    async def _checkAuth(self, core):
        # data check auth layout (users, passwords, rules, admin, etc.)
        self.sorteq(list(core.auth.usersbyname.keys()), ['root', 'fred', 'bobo'])
        self.sorteq(list(core.auth.rolesbyname.keys()), ['all', 'cowboys', 'ninjas', 'friends'])
        self.sorteq(list(core.auth.rolesbyname.keys()), ['all', 'cowboys', 'ninjas', 'friends'])

        self.len(7, core.auth.authgates)  # 2 views, 2 layers, 2 triggers, 1 cortex
        self.len(2, [iden for iden, gate in core.auth.authgates.items() if gate.type == 'view'])
        self.len(2, [iden for iden, gate in core.auth.authgates.items() if gate.type == 'layer'])
        self.len(1, [iden for iden, gate in core.auth.authgates.items() if gate.type == 'cortex'])

        # TODO: Probe auth data structure for accuracy

        # trigger idens
        tagtrg = (await core.nodes('syn:trigger:cond=tag:add'))[0].ndef[1]
        nodetrg = (await core.nodes('syn:trigger:cond=node:add'))[0].ndef[1]

        # views
        views = list(core.views.keys())
        defview = views[0]
        secview = views[1]

        # bobo
        # - read main view
        # - read/write to forked view via role
        # - no access to triggers  # TODO
        # - can add/del bobotag but not trgtag
        async with core.getLocalProxy(user='bobo') as proxy:
            self.gt(await proxy.count('inet:ipv4'), 0)
            await self.asyncraises(s_exc.AuthDeny, proxy.count('[inet:ipv4=10.10.10.10]'))
            await self.asyncraises(s_exc.StormRuntimeError, proxy.count(f'trigger.del {tagtrg}'))
            await self.asyncraises(s_exc.StormRuntimeError, proxy.count(f'trigger.del {nodetrg}'))

            self.gt(await proxy.count('inet:ipv4 [+#bobotag]'), 0)
            await self.asyncraises(s_exc.AuthDeny, proxy.count('#trgtag [-#trgtag]'))
            await self.asyncraises(s_exc.AuthDeny, proxy.count('inet:ipv4 [+#newbobotag]'))

            self.gt(await proxy.count('inet:ipv4', opts={'view': secview}), 0)
            self.gt(await proxy.count('[inet:ipv4=10.9.10.1]', opts={'view': secview}), 0)

        ## user permissions
        # fred
        # - read to main view
        # - read access to forked view via rule
        # - get/add triggers, but not delete  # TODO
        # - can add/del trgtag but not bobotag
        async with core.getLocalProxy(user='fred') as proxy:
            self.gt(await proxy.count('inet:ipv4'), 0)
            await self.asyncraises(s_exc.AuthDeny, proxy.count('[inet:ipv4=10.10.10.10]'))
            # await self.asyncraises(s_exc.StormRuntimeError, proxy.count(f'trigger.del {tagtrg}'))
            # await self.asyncraises(s_exc.StormRuntimeError, proxy.count(f'trigger.del {nodetrg}'))

            self.gt(await proxy.count('inet:ipv4 [+#trgtag]'), 0)
            await self.asyncraises(s_exc.AuthDeny, proxy.count('#trgtag [-#bobotag]'))
            await self.asyncraises(s_exc.AuthDeny, proxy.count('inet:ipv4 [+#newfredtag]'))

            self.gt(await proxy.count('inet:ipv4', opts={'view': secview}), 0)
            await self.asyncraises(s_exc.AuthDeny, proxy.count('[inet:ipv4=10.9.10.1]', opts={'view': secview}))

        # root
        # - read/write to main view
        # - read/write to forked view  # TODO
        # - get/del triggers
        async with core.getLocalProxy(user='root') as proxy:
            self.gt(await proxy.count('inet:ipv4'), 0)
            self.gt(await proxy.count('[inet:ipv4=10.10.10.11]'), 0)
            self.eq(2, await proxy.count('syn:trigger'))

            await proxy.eval(f'$lib.trigger.del({tagtrg})').list()
            await proxy.eval(f'$lib.trigger.del({nodetrg})').list()
            self.eq(0, await proxy.count('syn:trigger'))

    async def test_migr_nexus(self):
        conf = {
            'src': None,
            'dest': None,
            'migrops': None,
        }

        async with self._getTestMigrCore(conf) as (tdata, dest, locallyrs, migr):
            await migr.migrate()

            await self._checkStats(tdata, migr, locallyrs)

            # test dump errors
            dumpf = await migr.dumpErrors()
            self.nn(dumpf)

            errs = []
            with open(dumpf, 'rb') as fd:
                errs = s_msgpack.un(fd.read())

            self.len(2, errs)
            for err in errs:
                err['val']['node'][1]['props'].pop('.created')
            self.isin(MIGR_ERR, errs)

            await migr.fini()

            # startup 0.2.0 core
            async with await s_cortex.Cortex.anit(dest, conf=None) as core:
                # check that nexus root has offsets from migration
                self.gt(await core.getNexusOffs(), 1)

                # check core data
                await self._checkCore(core, tdata)
                await self._checkAuth(core)

    async def test_migr_nexusoff(self):
        conf = {
            'src': None,
            'dest': None,
            'addmode': 'nonexus',
            'safetyoff': True,
            'migrops': None,
        }

        async with self._getTestMigrCore(conf) as (tdata, dest, locallyrs, migr):
            await migr.migrate()

            await self._checkStats(tdata, migr, locallyrs)

            await migr.fini()

            # startup 0.2.0 core
            async with await s_cortex.Cortex.anit(dest, conf=None) as core:
                # check that nexus root has *no* offsets from migration
                self.eq(await core.getNexusOffs(), 0)

                # check core data
                await self._checkCore(core, tdata)
                await self._checkAuth(core)

    async def test_migr_editor(self):
        conf = {
            'src': None,
            'dest': None,
            'addmode': 'editor',
            'migrops': None,
        }

        async with self._getTestMigrCore(conf) as (tdata, dest, locallyrs, migr):
            await migr.migrate()

            await self._checkStats(tdata, migr, locallyrs)

            await migr.fini()

            # startup 0.2.0 core
            async with await s_cortex.Cortex.anit(dest, conf=None) as core:
                # check that nexus root has *no* offsets from migration
                self.eq(await core.getNexusOffs(), 0)

                # check core data
                await self._checkCore(core, tdata)
                await self._checkAuth(core)

    async def test_migr_restart(self):
        conf = {
            'src': None,
            'dest': None,
            'migrops': None,
        }

        async with self._getTestMigrCore(conf) as (tdata0, dest0, locallyrs0, migr0):
            await migr0.migrate()

            await self._checkStats(tdata0, migr0, locallyrs0)

            await migr0.fini()

            # run migration again
            conf['dest'] = dest0

            async with self._getTestMigrCore(conf) as (tdata, dest, locallyrs, migr):
                # check form counts
                fcntprnt = await migr.formCounts()
                self.len(2, fcntprnt)
                fnum = len([x for x in tdata['podes'] if x[0][0] == 'inet:fqdn'])
                self.isin(f'inet:fqdn{fnum}{fnum}0', '_'.join(fcntprnt).replace(' ', ''))

                # check that destination is populated before starting migration
                iden = locallyrs[0]
                lyrslab = os.path.join(dest, 'layers', iden, 'layer_v2.lmdb')
                self.true(os.path.exists(lyrslab))

                await migr.migrate()

                await self._checkStats(tdata, migr, locallyrs)

                await migr.fini()

                # startup 0.2.0 core
                async with await s_cortex.Cortex.anit(dest, conf=None) as core:
                    # check core data
                    await self._checkCore(core, tdata)
                    await self._checkAuth(core)

                    # check that hive information didn't get duplicated
                    hnode = await core.hive.open(('cortex', 'storage'))
                    hdict = await hnode.dict()
                    self.len(1, [x for x in hdict.items()])
