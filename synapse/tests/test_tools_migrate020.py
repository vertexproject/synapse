import os
import copy
import json
import contextlib

import synapse.tests.utils as s_t_utils

import synapse.lib.msgpack as s_msgpack

import synapse.tools.migrate_020 as s_migr

REGR_REPO = '/home/mike/git/synapse-regression'  # TODO hard-coded for testing, replace with utils.getRegrDir
REGR_DIR = '0.1.51-migr'

# Nodes that are expected to be unmigratable
NOMIGR_NDEF = [
    ["migr:test", 22],
]

# Error log to be generated by migr:test
# .created val removed since this will update when the regression repo is updated
MIGR_ERR = {
    'migrop': 'nodes',
    'logtyp': 'error',
    'key': b'\xc8ak\x08\xb8\x8fJ\xcd\xad/\xc4F\x08\x7f@\xc9k\xf8\xc4\xca\x807|\xacK\xe5\xff<\x88+7\xef',
    'val': {
        'mesg': "Unable to determine stortype for migr:test: 'NoneType' object has no attribute 'type'",
        'node': (
            b'\xc8ak\x08\xb8\x8fJ\xcd\xad/\xc4F\x08\x7f@\xc9k\xf8\xc4\xca\x807|\xacK\xe5\xff<\x88+7\xef',
            {
                'ndef': ('*migr:test', 22),
                'props': {'bar': 'spam'},
                'tags': {}, 'tagprops': {}
            }
        )
    }
}

def getAssetBytes(*paths):
    fp = os.path.join(*paths)
    assert os.path.isfile(fp)
    with open(fp, 'rb') as f:
        byts = f.read()
    return byts

def getAssetJson(*paths):
    byts = getAssetBytes(*paths)
    obj = json.loads(byts.decode())
    return obj

def convertJsonLists(elm):
    '''
    Recursively convert lists to tuples for equality comparisons.
    '''

    if isinstance(elm, list):
        for i, e in enumerate(elm):
            elm[i] = convertJsonLists(e)

        return tuple(elm)

    elif isinstance(elm, dict):
        for k, v in elm.items():
            elm[k] = convertJsonLists(v)

        return elm

    else:
        return elm

class MigrationTest(s_t_utils.SynTest):

    @contextlib.asynccontextmanager
    async def _getTestMigrCore(self, conf):
        '''
        Use regression cortex as the base migration dirn.

        Args:
            conf (dict): Migration tool configuration

        Yields:
            (list): List of podes in the cortex
            (s_migr.Migrator): Migrator service object
            (tuple): test data, dest dirn, dest local layers, Migrator
        '''
        path_cortex = ('cortexes', REGR_DIR)
        path_assets = ('assets', REGR_DIR)

        regr = os.path.join(REGR_REPO, *path_cortex)
        assets = os.path.join(REGR_REPO, *path_assets)

        # get test data
        tdata = {}
        podesj = getAssetJson(assets, 'podes.json')
        ndj = getAssetJson(assets, 'nodedata.json')

        # strip out data we don't expect to migrate
        podesj = [p for p in podesj if p[0] not in NOMIGR_NDEF]
        ndj = [nd for nd in ndj if nd[0] not in NOMIGR_NDEF]

        tdata['podes'] = convertJsonLists(podesj)
        tdata['nodedata'] = convertJsonLists(ndj)

        # initialize migration tool
        with self.getTestDir(copyfrom=regr) as src:
            with self.getTestDir(copyfrom=conf.get('dest')) as dest:
                tconf = copy.deepcopy(conf)
                tconf['src'] = src
                tconf['dest'] = dest

                locallyrs = os.listdir(os.path.join(src, 'layers'))

                async with await s_migr.Migrator.anit(tconf) as migr:
                    yield tdata, dest, locallyrs, migr

    async def _checkStats(self, tdata, migr, iden):
        '''
        Verify that the stats for what data has been migrated matches the test data
        '''
        tpodes = tdata['podes']
        tnodedata = tdata['nodedata']

        ipv4_cnt = len([x for x in tpodes if x[0][0] == 'inet:ipv4'])
        bytes_cnt = len([x for x in tpodes if x[0][0] == 'file:bytes'])
        tag_cnt = len([x for x in tpodes if x[0][0] == 'syn:tag'])

        nodedata_cnt = sum([len(x[1]) for x in tnodedata])

        stats = [log async for log in migr._migrlogGet('nodes', 'stat', f'{iden}:form')]
        self.gt(len(stats), 0)
        for stat in stats:
            skey = stat['key']
            sval = stat['val']  # (src_cnt, dest_cnt)

            if skey.endswith('inet:ipv4'):
                self.eq((ipv4_cnt, ) * 2, sval)
            elif skey.endswith('file:bytes'):
                self.eq((bytes_cnt, ) * 2, sval)
            elif skey.endswith('syn:tag'):
                self.eq((tag_cnt, ) * 2, sval)

        totnodes = [log async for log in migr._migrlogGet('nodes', 'stat', f'{iden}:totnodes')]
        self.eq(len(tpodes), totnodes[0]['val'][1])  # dest_cnt

        totnodedata = [log async for log in migr._migrlogGet('nodedata', 'stat', f'{iden}:totnodes')]
        self.eq(nodedata_cnt, totnodedata[0]['val'][1])  # dest_cnt

    async def _checkCore(self, core, tdata):
        '''
        Verify data in the migrated to 0.2.x cortex.
        '''

        # test validation data
        tpodes = tdata['podes']
        tnodedata = tdata['nodedata']

        # check all nodes
        nodes = await core.nodes('.created -meta:source:name=test')

        podes = [n.pack(dorepr=True) for n in nodes]
        self.gt(len(podes), 0)
        self.eq(podes, tpodes)

        nodedata = []
        for n in nodes:
            nodedata.append([n.ndef, [nd async for nd in n.iterData()]])
        nodedata = convertJsonLists(nodedata)
        self.eq(nodedata, tnodedata)

        # manually check node subset
        self.len(1, await core.nodes('inet:ipv4=1.2.3.4'))
        self.len(2, await core.nodes('inet:dns:a:ipv4=1.2.3.4'))

        # check that triggers are active
        root = await core.auth.getUserByName('root')
        triggers = await core.view.packTriggers(root.iden)
        # TODO: trigger check
        tnodes = await core.nodes('[ inet:ipv4=9.9.9.9 ]')
        # self.nn(tnodes[0].tags.get('trgtag'))

    async def test_migr_nexus(self):
        conf = {
            'src': None,
            'dest': None,
            'migrops': [
                'dirn',
                'dmodel',
                'hiveauth',
                'hivestor',
                'hivelyr',
                'nodes',
                'nodedata',
            ],
        }

        async with self._getTestMigrCore(conf) as (tdata, dest, locallyrs, migr):
            await migr.migrate()

            iden = locallyrs[0]  # update if regression cortex has more local layers

            await self._checkStats(tdata, migr, iden)

            # test dump errors
            dumpf = await migr.dumpErrors()
            self.nn(dumpf)

            errs = []
            with open(dumpf, 'rb') as fd:
                for line in fd:
                    errs.append(s_msgpack.un(line))

            self.len(1, errs)
            errs[0]['val']['node'][1]['props'].pop('.created')
            self.eq(errs[0], MIGR_ERR)

            await migr.fini()

            # startup 0.2.0 core
            async with self.getTestCore(dirn=dest) as core:
                # check that nexus root has offsets from migration
                self.gt(await core.getNexusOffs(), 1)

                # check core data
                await self._checkCore(core, tdata)

    async def test_migr_nexusoff(self):
        conf = {
            'src': None,
            'dest': None,
            'addmode': 'nonexus',
            'safetyoff': True,
            'migrops': None,
        }

        async with self._getTestMigrCore(conf) as (tdata, dest, locallyrs, migr):
            await migr.migrate()

            iden = locallyrs[0]  # update if regression cortex has more local layers

            await self._checkStats(tdata, migr, iden)

            await migr.fini()

            # startup 0.2.0 core
            async with self.getTestCore(dirn=dest) as core:
                # check that nexus root has *no* offsets from migration
                self.eq(await core.getNexusOffs(), 1)

                # check core data
                await self._checkCore(core, tdata)

    async def test_migr_editor(self):
        conf = {
            'src': None,
            'dest': None,
            'addmode': 'editor',
            'migrops': None,
        }

        async with self._getTestMigrCore(conf) as (tdata, dest, locallyrs, migr):
            await migr.migrate()

            iden = locallyrs[0]  # update if regression cortex has more local layers

            await self._checkStats(tdata, migr, iden)

            await migr.fini()

            # startup 0.2.0 core
            async with self.getTestCore(dirn=dest) as core:
                # check that nexus root has *no* offsets from migration
                self.eq(await core.getNexusOffs(), 1)

                # check core data
                await self._checkCore(core, tdata)

    async def test_migr_restart(self):
        conf = {
            'src': None,
            'dest': None,
            'migrops': None,
        }

        async with self._getTestMigrCore(conf) as (tdata0, dest0, locallyrs0, migr0):
            await migr0.migrate()

            iden = locallyrs0[0]  # update if regression cortex has more local layers

            await self._checkStats(tdata0, migr0, iden)

            await migr0.fini()

            # run migration again
            conf['dest'] = dest0

            async with self._getTestMigrCore(conf) as (tdata, dest, locallyrs, migr):
                # check that destination is populated before starting migration
                iden = locallyrs[0]
                lyrslab = os.path.join(dest, 'layers', iden, 'layer_v2.lmdb')
                self.true(os.path.exists(lyrslab))

                await migr.migrate()

                await self._checkStats(tdata, migr, iden)

                await migr.fini()

                # startup 0.2.0 core
                async with self.getTestCore(dirn=dest) as core:
                    # check core data
                    await self._checkCore(core, tdata)
