'''
Sync splices from an 0.1.x cortex to 0.2.x
'''
import os
import sys
import asyncio
import logging
import argparse

import synapse.exc as s_exc
import synapse.common as s_common
import synapse.telepath as s_telepath

import synapse.lib.cell as s_cell
import synapse.lib.base as s_base
import synapse.lib.time as s_time
import synapse.lib.queue as s_queue
import synapse.lib.layer as s_layer
import synapse.lib.config as s_config
import synapse.lib.output as s_output

logger = logging.getLogger(__name__)

class SyncMigratorApi(s_cell.CellApi):
    '''
    A telepath/cell API for the Sync service.
    '''
    async def status(self):
        return await self.cell.status()

    async def startSyncFromFile(self):
        return await self.cell.startSyncFromFile()

    async def startSyncFromLast(self):
        return await self.cell.startSyncFromLast()

class SyncMigrator(s_cell.Cell):
    cellapi = SyncMigratorApi
    confdefs = {
        'src': {
            'type': 'string',
            'description': 'Telepath URL for the source 0.1.x cortex.',
        },
        'dest': {
            'type': 'string',
            'description': 'Telepath URL for the destination 0.2.x cortex.',
        },
        'offsfile': {
            'type': 'string',
            'description': 'File path for the YAML file containing layer offsets.',
        },
        'poll_s': {
            'type': 'integer',
            'description': 'The number of seconds to wait between calls to src for new splices.',
            'default': 60,
        },
    }

    async def __anit__(self, dirn, conf=None):
        await s_cell.Cell.__anit__(self, dirn, conf=conf)

        self.src = self.conf.get('src')
        self.dest = self.conf.get('dest')
        self.offsfile = self.conf.get('offsfile')
        self.poll_s = self.conf.get('poll_s')

        self.pull_fair_iter = 100
        self.push_fair_iter = 100
        self.err_lim = 10

        self.pull_offs = await self.hive.dict(('sync:pulloffs', ))
        self.push_offs = await self.hive.dict(('sync:pushoffs', ))
        self.errors = await self.hive.dict(('sync:errors', ))

        self.model = {}

        self._pull_tasks = {}  # lyriden: Task
        self._push_tasks = {}

        self.pull_last_start = {}  # lyriden: epoch
        self.push_last_start = {}

        self._queues = {}  # lyriden: queue of splices

    async def status(self):
        '''
        Provide sync summary by layer

        Returns:
            (dict): Summary info with layer idens as keys
        '''
        retn = {}
        for lyriden, pulloffs in self.pull_offs.items():
            queue = self._queues.get(lyriden)
            if queue is not None:
                queuelen = len(queue.linklist)
            else:
                queuelen = None

            srclaststart = self.pull_last_start.get(lyriden)
            if srclaststart is not None:
                srclaststart = s_time.repr(srclaststart)

            destlaststart = self.pull_last_start.get(lyriden)
            if destlaststart is not None:
                destlaststart = s_time.repr(destlaststart)

            retn[lyriden] = {
                'src:nextoffs': pulloffs,
                'dest:nextoffs': await self.getLyrOffset('push', lyriden),
                'queuelen': queuelen,
                'src:task': await self._getTaskSummary(self._pull_tasks.get(lyriden)),
                'dest:task': await self._getTaskSummary(self._push_tasks.get(lyriden)),
                'src:laststart': srclaststart,
                'dest:laststart': destlaststart,
            }

        return retn

    async def _getTaskSummary(self, task):
        '''
        Creates a summary status dict for a Task.

        Args:
            task (Task):  Task to summarize

        Returns:
            (dict): Summary dict
        '''
        retn = {}
        if task is not None:
            done = task.done()
            retn = {'isdone': done}
            if done:
                retn['cancelled'] = task.cancelled()

                exc = task.exception()
                if exc is not None:
                    exc = task.exception()
                retn['exc'] = exc

        return retn

    async def startSyncFromFile(self):
        '''
        Start sync from layer offsets provided in offsfile generated by migration tool, e.g.
            <lyriden>
                created: <epochms>
                nextoffs: <int>
        '''
        lyroffs = s_common.yamlload(self.offsfile)

        for lyriden, info in lyroffs.items():
            nextoffs = info['nextoffs']
            logger.info(f'Starting Layer sync for {lyriden} from file offset {nextoffs}')
            await self._startLyrSync(lyriden, nextoffs)

    async def startSyncFromLast(self):
        '''
        Start sync from minimum last offset stored by push and pull.
        This can also be used to restart dead tasks.
        '''
        for lyriden, pulloffs in self.pull_offs.items():
            pushoffs = await self.getLyrOffset('push', lyriden)
            if pushoffs is None:
                nextoffs = pulloffs
            else:
                nextoffs = min(pulloffs, pushoffs)

            logger.info(f'Starting Layer sync for {lyriden} from last offset {nextoffs}')
            await self._startLyrSync(lyriden, nextoffs)

    async def _startLyrSync(self, lyriden, nextoffs):
        '''
        Starts up the sync process for a given layer and starting offset.
        Always retrieves a fresh datamodel.
        Creates layer queue and fires layer push/pull tasks if they do not already exist.

        Args:
            lyriden (str): Layer iden
            nextoffs (int): The layer offset to start sync from
        '''
        await self._setLyrOffset('pull', lyriden, nextoffs)

        await self._loadDatamodel()

        queue = self._queues.get(lyriden)
        if queue is None:
            queue = await s_queue.Window.anit(maxsize=None)
            self.onfini(queue.fini)
            self._queues[lyriden] = queue

        pulltask = self._pull_tasks.get(lyriden)
        if pulltask is None or pulltask.done():
            self._pull_tasks[lyriden] = self.schedCoro(self._srcPullLyrSplices(lyriden))

        pushtask = self._push_tasks.get(lyriden)
        if pushtask is None or pushtask.done():
            self._push_tasks[lyriden] = self.schedCoro(self._destPushLyrNodeedits(lyriden))

    async def _setLyrOffset(self, pushorpull, lyriden, offset):
        '''
        Stores the next offset to be read for a given layer.

        Args:
            pushorpull (str): "pull" or "push" to define context for stored offset
            lyriden (str): Layer iden
            offset (int): The offset to start sync from
        '''
        if pushorpull == 'pull':
            await self.pull_offs.set(lyriden, offset)
        elif pushorpull == 'push':
            await self.push_offs.set(lyriden, offset)

    async def getLyrOffset(self, pushorpull, lyriden):
        '''
        Retrieve the next layer offset to be read.

        Args:
            pushorpull (str): "pull" or "push" to define context for stored offset
            lyriden (str): Layer iden

        Returns:
            (int or None): Next offset or None if layer offset does not exist
        '''
        if pushorpull == 'pull':
            return self.pull_offs.get(lyriden, default=None)
        elif pushorpull == 'push':
            return self.push_offs.get(lyriden, default=None)

    async def _setLyrErr(self, lyriden, offset, err):
        errs = await self.getLyrErrs(lyriden)
        errs[offset] = err
        await self.errors.set(lyriden, errs)

    async def getLyrErrs(self, lyriden):
        return self.errors.get(lyriden, default={})

    async def _loadDatamodel(self):
        '''
        Retrieve the datamodel (with stortypes) from the destination cortex.
        '''
        async with await s_telepath.openurl(self.dest) as prx:
            model = await prx.getModelDict()
            self.model.update(model)

    def _getLayerUrl(self, tbase, lyriden):
        '''
        Helper for handling local/tcp urls.

        Args:
            tbase (str): Base telepath url of cell or tcp type
            lyriden (str): Layer iden

        Returns:
            (str): Url to the layer
        '''
        if tbase.startswith('cell:'):
            return os.path.join(tbase, 'layer', lyriden)
        if tbase.startswith('tcp:'):
            return os.path.join(tbase, 'cortex', 'layer', lyriden)
        raise Exception(f'Invalid telepath url base provided: {tbase}')

    async def _srcPullLyrSplices(self, lyriden):
        '''
        Open a proxy to the source layer and initiates splice reader.
        Intended to be run as a free-running task, and will poll for updates every poll_s.

        Args:
            lyriden (str): Layer iden
        '''
        trycnt = 0
        poll_s = self.poll_s
        turl = self._getLayerUrl(self.src, lyriden)
        while not self.isfini:
            try:
                trycnt += 1
                prx = await s_telepath.openurl(turl)
                trycnt = 0

                logger.info(f'Connected to source {lyriden}')

                while not prx.isfini:
                    queue = self._queues.get(lyriden)
                    startoffs = await self.getLyrOffset('pull', lyriden)

                    logger.debug(f'Pulling splices for layer {lyriden} starting from offset {startoffs}')

                    self.pull_last_start[lyriden] = s_common.now()
                    nextoffs = await self._srcIterLyrSplices(prx, startoffs, queue)

                    await self._setLyrOffset('pull', lyriden, nextoffs)

                    logger.debug(f'All splices from {lyriden} have been read; offsets: {startoffs} -> {nextoffs}')

                    await asyncio.sleep(poll_s)

            except asyncio.CancelledError:  # pragma: no cover
                raise
            except (ConnectionError, s_exc.IsFini):
                logger.exception(f'Source layer connection error cnt={trycnt}: {lyriden}')
                await asyncio.sleep(2 ** trycnt)
                continue

    async def _srcIterLyrSplices(self, prx, startoffs, queue):
        '''
        Iterate over available splices for a given source layer proxy, and push into queue

        Args:
            prx (s_telepath.Proxy): Proxy to source layer
            startoffs (int): Offset to start iterating from
            queue (s_queue.Window): Layer queue for splices

        Returns:
            (int): Next offset to start from when all splices have been read
        '''
        curoffs = startoffs
        fair_iter = self.pull_fair_iter
        async for splice in prx.splices(startoffs, -1):
            await queue.put((curoffs, splice))

            curoffs += 1

            if curoffs % fair_iter == 0:
                await asyncio.sleep(0)

        return curoffs

    async def _trnNodeSplicesToNodeedit(self, ndef, splices):
        '''
        Translate a batch of splices for a given node into a nodeedit set

        Args:
            ndef (tuple): (<form>, <valu>)
            splices (list): [ (<edit>, {<splice info>}), ...]

        Returns:
            (tuple): (cond, nodeedit, meta)
                cond: None or error dict
                nodeedit: (<buid>, <form>, [edits]) where edits is list of (<type>, <info>)
                meta: nodeedit meta dict
        '''
        buid = s_common.buid(ndef)
        form = ndef[0]
        fval = ndef[1]
        meta = None

        stype_f = await self._destGetStortype(form=form)
        if stype_f is None:
            err = {'mesg': f'Unable to determine stortype type for form {form}', 'splices': splices}
            logger.warning(err['mesg'])
            return err, None, None

        edits = []

        for splice in splices:
            spedit = splice[0]
            props = splice[1]

            # by definition all of these splices have the same meta (same node and same prov)
            if meta is None:
                meta = {k: v for k, v in props.items() if k in ('time', 'user', 'prov')}

            if spedit == 'node:add':
                edit = s_layer.EDIT_NODE_ADD
                edits.append((edit, (fval, stype_f)))

            elif spedit == 'node:del':
                edit = s_layer.EDIT_NODE_DEL
                edits.append((edit, (fval, stype_f)))

            elif spedit in ('prop:set', 'prop:del'):
                prop = props.get('prop')
                pval = props.get('valu')

                stype_p = await self._destGetStortype(form=form, prop=prop)
                if stype_p is None:
                    err = {'mesg': f'Unable to determine stortype type for prop {form}:{prop}', 'splice': splice}
                    logger.warning(err)
                    return err, None, None

                if spedit == 'prop:set':
                    edit = s_layer.EDIT_PROP_SET
                    edits.append((edit, (prop, pval, None, stype_p)))

                elif spedit == 'prop:del':
                    edit = s_layer.EDIT_PROP_DEL
                    edits.append((edit, (prop, pval, stype_p)))

            elif spedit in ('tag:add', 'tag:del'):
                tag = props.get('tag')
                tval = props.get('valu')
                toldv = props.get('oldv')

                if spedit == 'tag:add':
                    edit = s_layer.EDIT_TAG_SET
                    edits.append((edit, (tag, tval, toldv)))

                elif spedit == 'tag:del':
                    edit = s_layer.EDIT_TAG_DEL
                    edits.append((edit, (tag, tval)))

            elif spedit in ('tag:prop:set', 'tag:prop:del'):
                tag = props.get('tag')
                prop = props.get('prop')
                tval = props.get('valu')
                tcurv = props.get('curv')

                stype_tp = await self._destGetStortype(tagprop=prop)
                if stype_tp is None:
                    err = {'mesg': f'Unable to determine stortype type for tag prop {tag}:{prop}', 'splice': splice}
                    logger.warning(err)
                    return err, None, None

                if spedit == 'tag:prop:set':
                    edit = s_layer.EDIT_TAGPROP_SET
                    edits.append((edit, (tag, prop, tval, tcurv, stype_tp)))

                elif spedit == 'tag:prop:del':
                    edit = s_layer.EDIT_TAGPROP_DEL
                    edits.append((edit, (tag, prop, tval, stype_tp)))

            else:
                err = {'mesg': 'Unrecognized splice edit', 'splice': splice}
                logger.warning(err)
                return err, None, None

        return None, (buid, form, edits), meta

    async def _destGetStortype(self, form=None, prop=None, tagprop=None):
        '''
        Get the stortype integer for a given form, form prop, or tag prop.

        Args:
            form (str or None): Form name
            prop (str or None): Prop name (form must be specified in this case)
            tagprop (str or None): Tag prop name

        Returns:
            (int or None): Stortype integer or None if not found
        '''
        mtype = None

        if form is not None:
            if prop is None:
                mtype = form
            else:
                mtype = self.model['forms'].get(form, {})['props'].get(prop, {})['type'][0]

        elif tagprop is not None:
            mtype = self.model['tagprops'].get(tagprop, {})['type'][0]

        return self.model['types'].get(mtype, {}).get('stortype')

    async def _destPushLyrNodeedits(self, lyriden):
        '''
        Open a proxy to the given destination layer and initiate the queue reader.
        Intended to be run as a free-running task.

        Args:
            lyriden (str): Layer iden
        '''
        trycnt = 0
        while not self.isfini:
            try:
                trycnt += 1
                prx = await s_telepath.openurl(self._getLayerUrl(self.dest, lyriden))
                trycnt = 0

                logger.info(f'Connected to destination {lyriden}')

                queue = self._queues.get(lyriden)

                logger.debug(f'Starting {lyriden} splice queue reader')

                self.push_last_start[lyriden] = s_common.now()
                await self._destIterLyrNodeedits(prx, queue, lyriden)

                logger.warning(f'{lyriden} splice queue reader has stopped')

            except asyncio.CancelledError:  # pragma: no cover
                raise
            except (ConnectionError, s_exc.IsFini):
                logger.exception(f'Destination layer connection error cnt={trycnt}: {lyriden}')
                await asyncio.sleep(2 ** trycnt)
                continue

    async def _destIterLyrNodeedits(self, prx, queue, lyriden):
        '''
        Batch available source splices in a queue as nodeedits and push to the destination layer proxy.
        Nodeedit boundaries are defined by the ndef and prov iden.
        Will run as long as queue is not fini'd.

        Args:
            prx (s_telepath.Proxy): Proxy to destination layer
            queue (s_queue.Window): Layer queue for splices
            lyriden (str): Layer iden
        '''
        fair_iter = self.push_fair_iter
        err_lim = self.err_lim

        ndef = None
        prov = None
        nodesplices = []
        nodespliceoffs = []

        cnt = 0
        errs = 0
        async for offs, splice in queue:
            queuelen = len(queue.linklist)
            next_ndef = splice[1]['ndef']
            next_prov = splice[1].get('prov')

            # current splice is a new node or has new prov iden or the queue is empty
            # so create prior node nodeedit and push to destination layer
            if ndef is not None and (next_ndef != ndef or (prov is not None and next_prov != prov) or queuelen == 0):
                err, ne, meta = None, None, None

                try:
                    err, ne, meta = await self._trnNodeSplicesToNodeedit(ndef, nodesplices)
                    if err is None:
                        await prx.storNodeEditsNoLift([ne], meta)
                        await self._setLyrOffset('push', lyriden, offs + 1)

                except asyncio.CancelledError:  # pragma: no cover
                    raise
                except (ConnectionError, s_exc.IsFini):
                    # put back last and nodesplices
                    queue.linklist.appendleft((offs, splice))
                    qadd = zip(reversed(nodespliceoffs), reversed(nodesplices))
                    queue.linklist.extendleft(qadd)
                    raise
                except Exception as e:
                    err = {'mesg': s_common.excinfo(e), 'splices': nodesplices, 'nodeedits': ne, 'meta': meta}
                    logger.warning(err['mesg'])

                if err is not None:
                    errs += 1
                    await self._setLyrErr(lyriden, offs, err)
                    if errs >= err_lim:
                        raise Exception('Error limit reached')

                nodesplices = []
                nodespliceoffs = []

            ndef = next_ndef
            prov = next_prov
            nodesplices.append(splice)
            nodespliceoffs.append(offs)

            cnt += 1

            if queuelen == 0:
                logger.debug(f'{lyriden} queue reader status: read={cnt}, errs={errs}, size={len(queue.linklist)}')
            elif cnt % 100000 == 0:
                logger.info(f'{lyriden} queue reader status: read={cnt}, errs={errs}, size={len(queue.linklist)}')

            if queuelen == 0 or cnt % fair_iter == 0:
                await asyncio.sleep(0)

def getParser():
    https = os.getenv('SYN_UNIV_HTTPS', '4443')
    telep = os.getenv('SYN_UNIV_TELEPATH', 'tcp://0.0.0.0:27492/')
    telen = os.getenv('SYN_UNIV_NAME', None)

    pars = argparse.ArgumentParser(prog='synapse.tools.sync_020')
    s_config.common_argparse(pars, https=https, telep=telep, telen=telen)

    return pars

async def cb(cell, opts, outp):
    await s_config.common_cb(cell, opts, outp)

async def main(argv, outp=s_output.stdout):
    pars = getParser()
    cell = await s_config.main(SyncMigrator, argv, pars=pars, cb=cb, outp=outp)
    return cell

if __name__ == '__main__':  # pragma: no cover
    asyncio.run(s_base.main(main(sys.argv[1:])))
