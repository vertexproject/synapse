# Python CircleCI 2.0 configuration file
#
# Check https://circleci.com/docs/2.0/language-python/ for more details
#
version: 2.1

orbs:
  gh-release: vertexproject/github-release@0

commands:
  do_report_coverage:
    description: "Codecov report upload"
    steps:
      - run:
          name: Upload Coverage Results
          command: |
            # Download and verify the codecov binary
            curl https://keybase.io/codecovsecurity/pgp_keys.asc | gpg --import # One-time step
            curl -Os https://uploader.codecov.io/latest/linux/codecov
            curl -Os https://uploader.codecov.io/latest/linux/codecov.SHA256SUM
            curl -Os https://uploader.codecov.io/latest/linux/codecov.SHA256SUM.sig
            gpg --verify codecov.SHA256SUM.sig codecov.SHA256SUM
            shasum -a 256 -c codecov.SHA256SUM
            chmod +x codecov
            # Activate our venv and generate a xml report
            . venv/bin/activate
            python -m coverage xml
            # Execute the binary...
            ./codecov \
              -t "${CODECOV_TOKEN}" \
              -n "${CODECOV_PREFIX}${PYVERS}node${CIRCLE_NODE_INDEX}" \
              -F "${CODECOV_FLAG}" \
              -f ./coverage.xml \
              -v \
              -Z || echo 'Codecov upload failed'

  do_venv_setup:
    description: "Setup venv for testing"
    steps:
      - run:
          name: setup venv
          command: |
            python3 -m venv --copies venv
            . venv/bin/activate
            python3 -m pip install -U wheel pip setuptools
            python3 -m pip install -U -r requirements_dev.txt

      - run:
          name: install synapse
          command: |
            . venv/bin/activate
            python3 -m pip install -U --upgrade-strategy=eager -e .

  do_test_execution:
    description: "Execute unit tests via pytest"
    steps:
      - run:
          name: run tests
          command: |
            . venv/bin/activate
            mkdir test-reports
            circleci tests glob synapse/tests/test_*.py synapse/vendor/**/test_*.py | \
              circleci tests run \
                --timings-type=name \
                --command="xargs python3 -m pytest -n 8 --dist worksteal -v -rs --durations 6 -p no:logging --junitxml=test-reports/junit.xml -o junit_family=xunit1 ${COVERAGE_ARGS}"

  test_steps_doc:
    description: "Documentation test steps"
    steps:
      - checkout

      - run:
          name: install deps
          command: |
            sudo apt-get update
            sudo apt-get -y install pandoc

      - run:
          name: python version dump
          command: |
            python -c "import sys; print(sys.version)" | tee -a /tmp/python.version

      - restore_cache:
          keys:
            - v5-docvenv-{{ .Environment.CIRCLE_JOB }}-{{ .Branch }}-{{ checksum "pyproject.toml" }}-{{ checksum "/tmp/python.version" }}

      - run:
          name: setup venv
          command: |
            python3 -m venv --copies venv
            . venv/bin/activate
            python3 -m pip install -U wheel pip setuptools

      - run:
          name: install synapse requirements
          command: |
            . venv/bin/activate
            python3 -m pip install -U --upgrade-strategy=eager -r requirements_doc.txt

      - save_cache:
          paths:
            - ./venv
          key: v5-docvenv-{{ .Environment.CIRCLE_JOB }}-{{ .Branch }}-{{ checksum "pyproject.toml" }}-{{ checksum "/tmp/python.version" }}

      - run:
          name: executing docs test / build
          command: |
            . venv/bin/activate
            ./scripts/doctests.py
            cd docs
            make html

  test_steps_python:
    description: "Python test steps"
    steps:
      - checkout

      - run:
          # Run this first so we fail on syntax errors before installing a bunch
          # of stuff and doing a bunch of work. It's easier now that we're only
          # a single runner using xdist.
          name: syntax
          command: |
            pip install "pycodestyle>=2.10.0,<3.0.0"
            if [ -n "${RUN_SYNTAX}" ]; then pycodestyle synapse; fi;
            if [ -n "${RUN_SYNTAX}" ]; then pycodestyle scripts; fi;

      - run:
          name: checkout regression repo
          command: |
            git clone https://github.com/vertexproject/synapse-regression ~/git/synapse-regression

      - run:
          name: python version dump
          command: |
            python -c "import sys; print(sys.version)" | tee -a /tmp/python.version

      - restore_cache:
          keys:
            - v5-venv-{{ .Environment.CIRCLE_JOB }}-{{ .Branch }}-{{ checksum "pyproject.toml" }}-{{ checksum "/tmp/python.version" }}

      - do_venv_setup

      - save_cache:
          paths:
            - ./venv
          key: v5-venv-{{ .Environment.CIRCLE_JOB }}-{{ .Branch }}-{{ checksum "pyproject.toml" }}-{{ checksum "/tmp/python.version" }}

      - do_test_execution

      - do_report_coverage

      - store_test_results:
          path: test-reports

      - store_artifacts:
          path: test-reports

  deploy_pypi_prologue:
    description: "Common Pypi prologue"
    steps:
      - checkout

      - run:
          name: python version dump
          command: |
            python -c "import sys; print(sys.version)" | tee -a /tmp/python.version

      - restore_cache:
          keys:
            - v5-venv-{{ .Environment.CIRCLE_JOB }}-{{ .Branch }}-{{ checksum "pyproject.toml" }}-{{ checksum "/tmp/python.version" }}

      - run:
          name: install python dependencies
          command: |
            python3 -m venv venv
            . venv/bin/activate
            python3 -m pip install -U wheel pip setuptools twine build
            python3 -m pip install -U -r requirements_dev.txt

      - save_cache:
          paths:
            - ./venv
          key: v5-venv-{{ .Environment.CIRCLE_JOB }}-{{ .Branch }}-{{ checksum "pyproject.toml" }}-{{ checksum "/tmp/python.version" }}

      - run:
          name: init .pypirc
          command: |
            echo -e "[pypi]" >> ~/.pypirc
            echo -e "username = $PYPI_USERNAME" >> ~/.pypirc
            echo -e "password = $PYPI_PASSWORD" >> ~/.pypirc

      - run:
          name: set commit
          command: |
            . venv/bin/activate
            python ./scripts/replace_commit.py

  deploy_pypi_tag_verify:
    description: "Verify the git tag"
    steps:
      - run:
          name: verify git tag vs. version
          command: |
            . venv/bin/activate
            python ./scripts/verify_version.py

  deploy_pypi_sdist_build:
    description: "Build sdist packages for pypi"
    steps:
      - run:
          name: create packages
          command: |
            . venv/bin/activate
            python -m build --sdist

      - run:
          name: smoke packages
          command: |
            mkdir -p /tmp/sdisttest
            python3 -m venv /tmp/sdisttest/venv
            cp dist/*.tar.gz /tmp/sdisttest
            cd /tmp/sdisttest
            . ./venv/bin/activate
            python3 -m pip install -U pip twine setuptools
            python3 -m twine check *.tar.gz
            python3 -m pip install *.tar.gz
            python3 -c "$PYPI_SMOKE_CODE"
            deactivate

  deploy_pypi_wheel_build:
    description: "Build wheel packages for pypi"
    steps:
      - run:
          name: create packages
          command: |
            . venv/bin/activate
            export DIST_EXTRA_CONFIG=/tmp/build-opts.cfg
            echo -e "[bdist_wheel]\npython_tag=$PYTHON_TAG" > $DIST_EXTRA_CONFIG
            python -m build --wheel

      - run:
          name: smoke packages
          command: |
            mkdir -p /tmp/wheeltest
            python3 -m venv /tmp/wheeltest/venv
            cp dist/*.whl /tmp/wheeltest
            cd /tmp/wheeltest
            . ./venv/bin/activate
            python3 -m pip install -U wheel pip twine setuptools
            python3 -m twine check *.whl
            python3 -m pip install *.whl
            python3 -c "$PYPI_SMOKE_CODE"
            deactivate

  deploy_pypi_upload:
    description: "Upload packages to pypi"
    steps:
      - run:
          name: upload to pypi
          command: |
            . venv/bin/activate
            twine upload dist/*

  
  do_docker_prep:
    description: "Install packages and set commit."
    steps:
      - run:
          name: install packages
          command: |
            apk add python3 py3-pip git "cosign~2." bash
      - run:
          name: install awscli
          command: |
            python3 -m pip install "pyyaml<5.4"
            python3 -m pip install awscli
      - run:
          name: setcommit
          command: |
            python3 scripts/replace_commit.py

  do_docker_login:
    description: "Login to docker"
    steps:
      - run:
          name: "Login to primary registry"
          command: |
            if [ $DOCKER_PRIMARY_REGISTRY = docker.io/ ]
            then
              docker login --username "${DOCKER_USERNAME}" --password "${DOCKER_PASSWORD}"
            else
              aws ecr get-login-password | docker login --username AWS --password-stdin $AWS_ECR_REGISTRY
            fi
      - run:
          name: "Login to secondary registry"
          command: |
            if [ -z $DOCKER_FAILOVER ]
            then
              if [ $DOCKER_PRIMARY_REGISTRY = docker.io/ ]
              then
                aws ecr get-login-password | docker login --username AWS --password-stdin $AWS_ECR_REGISTRY
              else
                docker login --username "${DOCKER_USERNAME}" --password "${DOCKER_PASSWORD}"
              fi
            else
              echo "Not logging into secondary docker account."
            fi

  build_docker:
    description: "Build a docker image"
    parameters:
      image-tag:
        type: string
    steps:
      - checkout
      - setup_remote_docker
      - do_docker_prep
      - run:
          name: build images
          command: |
            docker/build_all.sh << parameters.image-tag >>
      - run:
          name: smoke test images
          command: |
            docker/scripts/test_all.sh << parameters.image-tag >>

  push_docker_image:
    description: "Push a docker image up to a registry"
    parameters:
      registry:
        type: string
      secondaryregistry:
        type: string
      image-tag:
        type: string
      source-tag:
        type: string
        default: ""
      cosign:
        type: boolean
        default: false
    steps:

      - do_docker_login

      - when:
          condition: << parameters.source-tag >>
          steps:
            - run:
                name: retag images
                command: |
                  docker/scripts/retag_all.sh << parameters.source-tag >> << parameters.image-tag >>

      - run:
          name: push images
          command: |
            docker/scripts/push_all.sh << parameters.image-tag >> << parameters.registry >> imageDigests.txt

      - when:
          condition: << parameters.cosign >>
          steps:
            - run:
                name: extract and setup certdir
                command: |
                  mkdir -p /mnt/ramdisk/certdir/cas/
                  mkdir -p /mnt/ramdisk/certdir/code/
                  mkdir -p /mnt/ramdisk/certdir/cosign/
                  echo $VTX_BUILD_CRT | base64 -d > /mnt/ramdisk/certdir/code/signer.crt
                  echo $VTX_BUILD_KEY | base64 -d > /mnt/ramdisk/certdir/code/signer.key
                  echo $VTX_BUILD_CA_FULLCHAIN | base64 -d > /mnt/ramdisk/certdir/cas/fullchain.crt

            - run:
                name: sign images
                command: |
                  # Generate a random password to encode the signing key with
                  export COSIGN_PASSWORD=`hexdump -vn16 -e'4/4 "%08X" 1 "\n"' /dev/urandom`

                  # Export the key material to /mnt/ramdisk/certdir/cosign/signer.key + signer.pub
                  cosign import-key-pair --verbose --key /mnt/ramdisk/certdir/code/signer.key -o /mnt/ramdisk/certdir/cosign/signer

                  # Sign the artifacts we just built!
                  cat imageDigests.txt | while read IMAGETOSIGN
                  do
                    echo 'Signing $IMAGETOSIGN'
                    cosign sign -a commit=<<pipeline.git.revision>> -a jobid=$CIRCLE_WORKFLOW_JOB_ID --certificate-chain /mnt/ramdisk/certdir/cas/fullchain.crt --cert /mnt/ramdisk/certdir/code/signer.crt --key /mnt/ramdisk/certdir/cosign/signer.key --tlog-upload=false $IMAGETOSIGN
                  done

            - run:
                name: clean up certdir
                command: |
                  dirs="/mnt/ramdisk/certdir/code /mnt/ramdisk/certdir/cosign"
                  echo "$dirs" | tr ' ' '\n' | while read dirn;
                  do
                    for f in $(ls $dirn)
                    do
                      fullpath=$dirn/$f
                      echo "Wiping $fullpath"
                      read blocks blocksize < <(stat -c "%b %B" ${fullpath})
                      dd if=/dev/zero bs=${blocksize} count=${blocks} of=${fullpath} conv=notrunc
                      sync $fullpath
                      rm ${fullpath}
                    done
                  done

      - run:
          name: copy image and signatures to secondary registry
          command: |
            if [ -z $DOCKER_FAILOVER ]
            then
              docker/scripts/copy_all.sh << parameters.image-tag >> << parameters.registry >> << parameters.secondaryregistry >>
            else
              echo "Skipping secondary registry copy."
            fi

  check_tag_for_major_release:
    description: "Check circle_tag to see if its a major release and export it, halt if not."
    steps:
      - run:
          name: check tag for major release
          command: |
            # Pull major tag
            IFS="."
            read MAJOR MINOR PATCH \<< EOF
            $CIRCLE_TAG
            EOF
            unset IFS
            # Exit early if we're a non-numeric patch value.
            echo $PATCH | grep -E "[^0-9]" && circleci-agent step halt && exit 0
            DOCKER_TAG=$MAJOR.x.x
            echo "Found DOCKER_TAG=${DOCKER_TAG}"
            echo "export DOCKER_TAG=${DOCKER_TAG}" >> $BASH_ENV

jobs:

  python311:
    resource_class: xlarge
    docker:
      - image: cimg/python:3.11
        environment:
          PYVERS: 3.11
          RUN_SYNTAX: 1
          SYN_VENDOR_TEST: 1
          CODECOV_FLAG: linux
          SYN_REGRESSION_REPO: ~/git/synapse-regression
          COVERAGE_FILE: test-reports/<< pipeline.git.revision >>/.coverage
          COVERAGE_ARGS: --cov synapse --cov-append

    working_directory: ~/repo

    steps:
      - test_steps_python

  python311_replay:
    resource_class: xlarge
    docker:
      - image: cimg/python:3.11
        environment:
          PYVERS: 3.11
          RUN_SYNTAX: 1
          CODECOV_FLAG: linux_replay
          SYN_REGRESSION_REPO: ~/git/synapse-regression
          COVERAGE_ARGS: --cov synapse
          SYNDEV_NEXUS_REPLAY: 1

    working_directory: ~/repo

    steps:
      - test_steps_python

  doctests:
    docker:
      - image: cimg/python:3.11
        environment:
          PYVERS: 3.11

    working_directory: ~/repo

    steps:
      - test_steps_doc

  python_package_smoketest:
    docker:
      - image: cimg/python:3.11
        environment:
          PYPI_SMOKE_CODE: import synapse; print(synapse.version)
          PYTHON_TAG: py311

    steps:
      - deploy_pypi_prologue
      - deploy_pypi_wheel_build
      - deploy_pypi_sdist_build

  deploy_pypi:
    docker:
      - image: cimg/python:3.11
        environment:
          PYPI_SMOKE_CODE: import synapse; print(synapse.version)
          PYTHON_TAG: py311

    steps:
      - deploy_pypi_prologue
      - deploy_pypi_tag_verify
      - deploy_pypi_wheel_build
      - deploy_pypi_sdist_build
      - deploy_pypi_upload

  build_docker_branch:
    docker:
      - image: docker:24.0.2
    steps:
      - build_docker:
          image-tag: ${CIRCLE_BRANCH//\//_}
      - push_docker_image:
          image-tag: ${CIRCLE_BRANCH//\//_}
          registry: ${DOCKER_PRIMARY_REGISTRY}
          secondaryregistry: ${DOCKER_SECONDARY_REGISTRY}

  build_docker_tag:
    docker:
      - image: docker:24.0.2
    # Use a shell override to force a login shell that loads profile for each step.
    shell: /bin/sh -leo pipefail
    environment:
      - BASH_ENV: /etc/profile
    steps:
      - build_docker:
          image-tag: ${CIRCLE_TAG}
      - push_docker_image:
          image-tag: ${CIRCLE_TAG}
          cosign: true
          registry: ${DOCKER_PRIMARY_REGISTRY}
          secondaryregistry: ${DOCKER_SECONDARY_REGISTRY}
      - check_tag_for_major_release
      - push_docker_image:
          image-tag: ${DOCKER_TAG}
          source-tag: ${CIRCLE_TAG}
          registry: ${DOCKER_PRIMARY_REGISTRY}
          secondaryregistry: ${DOCKER_SECONDARY_REGISTRY}

workflows:
  version: 2
  run_tests:
    jobs:
      - doctests:
          filters:
            tags:
              only: /.*/
            branches:
               only: /.*/

      - python311:
          filters:
            tags:
              only: /.*/
            branches:
              only: /.*/

      - python311_replay:
          filters:
            tags:
              only: /.*/
            branches:
              only:
                - master

      - python_package_smoketest:
          filters:
            tags:
              only: /.*/
            branches:
              only:
                - master

      - deploy_pypi:
          requires:
            - doctests
            - python311
            - python311_replay
            - python_package_smoketest
          context:
            - PublicPypiAccess
          filters:
            tags:
              only: /^v2\.[0-9]+\.[0-9]+((a|b|rc)[0-9]*)?$/
            branches:
              ignore: /.*/

      - gh-release/dorelease:
          requires:
            - doctests
            - python311
            - python311_replay
            - python_package_smoketest
          context:
            - GithubMachine
            - Mailgun
          filters:
            tags:
              only: /^v2\.[0-9]+\.[0-9]+((a|b|rc)[0-9]*)?$/
            branches:
              ignore: /.*/

      - build_docker_branch:
          requires:
            - doctests
            - python311
          context:
            - AWSEcrPusherOSS
            - SynapseDockerCloudUpload
            - VTXDockerControl
          filters:
            branches:
              only:
                - master

      - build_docker_tag:
          requires:
            - doctests
            - python311
          context:
            - AWSEcrPusherOSS
            - SynapseDockerCloudUpload
            - VTXCodeSign
            - VTXDockerControl
          filters:
            tags:
              only: /^v2\.[0-9]+\.[0-9]+((a|b|rc)[0-9]*)?$/
            branches:
              ignore: /.*/

  nightly:
    triggers:
      - schedule:
          cron: "0 12 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - doctests
      - python311

  weekly:
    triggers:
      - schedule:
          cron: "0 12 1 * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - python311_replay
