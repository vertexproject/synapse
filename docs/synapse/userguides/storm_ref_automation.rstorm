.. highlight:: none

.. storm-cortex:: default

.. _storm-ref-automation:

Storm Reference - Automation
============================

.. _auto-bkgd:

Background
----------

Synapse supports large-scale analysis over disparate data sources with speed and efficiency. Many features
that support this analysis are built into Synapse’s architecture, from performance-optimized indexing and
storage to an extensible data model that allows you to reason over data in a structured manner.

Synapse also supports large-scale analysis through the use of **automation.** Synapse’s automation features
include:

- `Triggers and Cron`_
- `Macros`_
- `Dmons`_

By making use of automation in Synapse, you can free analysts from performing tedious work and allow them
to focus on more detailed analysis and complex tasks. You can also scale analytical operations by limiting
the amount of work that must be performed manually.

Automation in Synapse uses the Storm query language: **anything that can be written in Storm can be automated,**
from the simple to the more advanced. Actions performed via automation are limited only by imagination and Storm
proficiency. Some automation is fairly basic ("if X occurs, do Y" or "once a week, update Z"). However, automation
can take advantage of all available Storm features, including subqueries, variables, libraries, control flow logic,
and so on.

.. _auto-consid:

Considerations
--------------

This section is **not** meant as a detailed guide on implementing automation. A few items are listed here
for consideration when planning the use of automation in your environment.

Permissions
+++++++++++

Permissions impact the use of automation in Synapse in various ways. In some cases, you must explicitly
grant permission for users to create and manage automation. In other cases, the permissions that a given
automated task runs under may vary based on the type of automation used. See the relevant sections below
for additional detail.

.. TIP::
  
  For a detailed discussion of permissions in Synapse, refer to the `Synapse Admin Guide`_.

Scope
+++++

Automation components vary with respect to where they reside and execute within Synapse; some elements are
global (within a Cortex) while some reside and execute within a specific :ref:`gloss-view`. Organizations
that make use of Synapse's fork and merge capabilities should refer to the sections below for inforamtion
on how views and layers may impact automation.

For a more general discussion of views and layers, including a discussion of forking and merging views, see
the :ref:`userguide_views_layers` section of the Synapse User Guide.

Testing
+++++++

Automation should **always** be tested before being placed into production. Storm used in automation
can be syntactically correct (uses proper Storm), but contain logical errors (fail to do what you
want it to do). Similarly, new automation may interact with existing automation in unexpected ways.
Test your automation in a development environment (either a separate development instance, or a separate
:ref:`gloss-fork` of your production view) before implementing it in production.

Use Cases
+++++++++

Organizations can implement automation as they see fit. Some automation may be enterprise-wide, used
to support an organization’s overall mission or analysis efforts. Other automation may be put in
place by individual analysts to support their own research efforts, either on an ongoing or temporary
basis.

Design
++++++

There are varying approaches for "how" to write and implement automation. For example:

- **Location of automation code.** The Storm code run by individual triggers and cron jobs can be written
  and stored as part of the automation itself. This approach helps keep automation "self-contained" and
  means the Storm executed by a given trigger or cron job is directly introspectable via Storm itself (as a
  property of ``syn:trigger`` or ``syn:cron`` nodes). However, it may provide less flexibility in
  executing the associated Storm compared with the use of macros.
  
  Alternatively, tasks such as triggers and cron jobs can be written to execute minimal Storm queries
  whose purpose is to call more extensive Storm stored centrally in macros. This approach consolidates
  much of the associated Storm, which may make it easier to manage and maintain. Storm placed in macros
  also provides flexibility as the macro can be called by a trigger, a cron job, or a user as part of
  a Storm query.

- **Size of automation.** Automation can be written as many small, individual elements. Each element can
  perform a relatively simple task, but the elements can work together like building blocks to orchestrate
  larger-scale operations. This approach keeps tasks "bite sized" and the Storm executed by a given piece
  of automation generally simpler. However it may result in a larger number of automation elements to
  maintain, and may make it more challenging to understand the potential interactions of so many different
  elements.
    
  Alternatively, automation can be implemented using fewer elements that perform larger, more unified
  tasks (or that consolidate numerous smaller tasks into a larger set of Storm code). This approach results
  in fewer automation elements overall, but typically requires you to write and maintain more advanced
  Storm (e.g., to create a small number of macros with switch or if/else statements to each manage a
  variety of tasks). However, the Storm is consolidated in a few locations, which may make managing
  and troubleshooting easier.

Each approach has its pros and cons; there is no single "right" way. In addition, you do not have to take
an "either / or" approach; what works best in your environment or for a particular task will depend on
your needs (and possibly some trial and error).

Governance / Management
+++++++++++++++++++++++

Consider any oversight or approval processes that you may need in order to implement and manage automation
effectively in your environment. Organization-wide automation requires coordination and oversight:

- Where multiple users have the ability to create automated tasks, it is possible for them to create
  duplicative or even conflicting automation. Consider who should be repsonsible for deconflicting
  automation to mitigate against these effects.

- Automation is often used to enrich indicators (i.e., query various third-party APIs to pull in more
  data related to a node). Some third-party APIs may impose query limits, may be subject to a license
  or subscription fee, or both. Consider how to balance effective use of automation without overusing
  or exceeding any applicable quotas.

- Some automation may be used to apply tags to nodes or "push" tags from one node to related nodes -
  effectively automating the process of making an analytical assertion. Consider carefully under what
  circumstances this should be automated, and who should review or approve the analysis logic used to
  make the assertion.


Automation and Error Handling
+++++++++++++++++++++++++++++

If the Storm executed by a piece of automation encounters an error condition, the automation will
cease execution and exit. For automation that operates over large numbers of nodes or performs a
long-running task, an unexpected error can cause the automation to "halt in the middle" and fail to
complete, which may be problematic in some cases.

In addition to general testing of your Storm code (and Storm logic!), using the :ref:`edit-try` when
adding or modifying data will ensure your Storm code will "warn and continue" if it encounters bad
data vs. generating an error and halting.

We also encourage you to build in additional error-checking and error-handling into your automation
as appropriate.

Users should keep the :ref:`storm-op-concepts` in mind when writing automation. Automation frequently
operates on nodes or other Synapse data; knowing what nodes are in the Storm pipeline for your
automation will help significantlty with troubleshooting any issues.


.. _auto-triggers-cron:

Triggers and Cron
-----------------

Triggers and cron are similar in terms of how they are implemented and managed.

- **Permissions.** Synapse uses permissions to determine who can create, modify, and delete triggers
  and cron jobs. These permissions must be explicitly granted to users and/or roles. See the `Cortex permissions`_
  section of the `Synapse Admin Guide`_ for a list of ``cron.*`` and ``trigger.*`` permissions.
    
- **Execution.** Both triggers and cron jobs execute with the permissions of a designated user associated
  with the individual trigger or cron job. By default, this is the user who creates the trigger or cron
  job. The user can be changed (e.g., for organizations that wish to use a dedicated account for
  automation tasks) using the ``$trigger.set()`` (:ref:`stormprims-trigger-set`) or ``$cronjob.set()``
  (:ref:`stormprims-cronjob-set`) methods, respectively.
  
- **Scope.** Both triggers and cron jobs run **within a specific view.** This view-specific behavior is
  transparent when using a simple Synapse implementation consisting of a single Cortex with a single layer
  and a single view (Synapse's default configuration). Organizations using multiple views or that
  frequently fork views should consider the impact of your view architecture on automation deployment
  and behavior.

.. NOTE::
  
  Cron and triggers are **fully automated** processes in Synapse. That is, once a cron job or trigger is
  created and enabled (and both are **enabled by default** as soon as they are created), they will execute
  without any further human intervention.

.. _auto-cron:

Cron
++++

Cron jobs in Synapse are similar to the well-known cron utility. Cron jobs execute their associated Storm
on a specified schedule. Cron jobs can be written to execute once (using the :ref:`storm-cron-at` command)
or on a recurring basis (using :rev:`storm-cron-add`).

.. TIP::
  
  When scheduling cron jobs, Synapse interprets all times as UTC.

Cron jobs have the following characteristics in Synapse 2.xx:

.. _auto-cron-config:

Configuration and Management
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- **Storage and Execution.** Cron jobs are stored **globally** (within the Cortex). However, cron jobs execute
  within a specific **view**. If the view that a cron job runs in is deleted, the cron job **remains** (within
  the Cortex) but is effectively orphaned until it is explicitly assigned to a new view (i.e., using the
  :ref:`stormlibs-lib-cron-move` library) or deleted if no longer needed.
  
  Because cron jobs are stored globally, when **viewing** cron jobs, (e.g., with the :ref:`storm-cron-list` command),
  Synapse returns all cron jobs in the Cortex, regardless of the view the ``cron.list`` command is executed in.
  
- **Permissions.** Cron jobs execute with the privileges of a designated user (typically the user who creates the
  cron job). We strongly encourage the use of least privilege; the cron job's account should have the permissions
  required to execute the associated Storm, but no more. One option is for organizations to create a dedicated
  account for use with automation in Synapse.
  
  The owner (creator) of a cron job can be modified using the Storm :ref:`stormlibs-lib-cron-get` library and
  :ref:`stormprims-cronjob-f527` primitive. For example:
  
  ::
    
    $mycron=$lib.cron.get(<cron_iden>) $mycron.set(creator, <new_creator_iden>)
  
  Users (and roles) cannot create or manage cron jobs by default. The various ``cron.*`` permissions must be granted
  to users or roles that should be allowed to work with cron jobs in your environment.
  
  See the `Cortex permissions`_ section of the `Synapse Admin Guide`_ for details on the ``cron.*`` permissions
  and associated gates.
  
  .. NOTE::
    
    Where a user has **admin** privileges, all permissions checks are bypassed. This means (for example) that
    users can create and manage cron jobs in views that they fork.

- **Managing Cron Jobs.** Cron jobs can be created, viewed, and managed using the various Storm :ref:`storm-cron`
  commands, the :ref:`stormprims-cronjob-f527` methods, or the :ref:`stormlibs-lib-cron` libraries.
  
  When a cron job is created, Synapse also generates a ``syn:cron`` runtime node ("runt node") with some
  details about the cron job available as properties on the node. While runt nodes are typically read-only,
  ``syn:cron`` nodes include ``:name`` and ``:doc`` secondary properties that can be set and modified via Storm
  (or configured via :ref:`gloss-optic`). This allows you to manage cron jobs by giving them meaningful names and
  descriptions. Changes to these properties will persist even after a Cortex restart.
  
  Runt nodes can be lifted, viewed, filtered, etc. just like other nodes in Synapse, which allows you to perform
  limited introspection_ of cron jobs using Storm.


.. _auto-cron-use:

Use Cases
~~~~~~~~~

Because cron jobs are scheduled, they are most appropriate for automating routine tasks, non-urgent tasks, or
resource-intensive tasks that should be scheduled to minimize impact on operations.

"What" a cron job does is limited only by your imagination (and your Storm skills). Examples of common cron use
cases include:

- **Data ingest.** Periodically ingest / synchronize data that you want to load into Synapse on a regular basis.

- **Housekeeping.** Perform one-time or periodic "maintenance" tasks. These may include one-time sweep to "backfill"
  missing data (like IP geolocation data) or a periodic sweep to check set missing properties (such as tag definitions).

- **Process intensive jobs.** Data enrichment may be resource intensive where it generates a significant number
  of write operations. If you reguarly perform routine (non-urgent) enrichment, it can be scheduled to run
  when it will have less impact on users.

- **Periodic hunting.** New data and annotations (tags) are continually added to Synapse. Encoding "hunt" logic
  in Storm and periodically running hunts can help ensure you are continually reviewing new data for updated
  indicators or activity.

.. TIP::
  
  A cron job can use Storm to call a macro, which may provide greater flexibility in storing and managing the
  job's Storm code.


.. _auto-cron-syntax:

Syntax
~~~~~~

Cron jobs are created, modified, viewed, enabled, disabled, and deleted using the Storm :ref:`storm-cron`
commands. In :ref:`gloss-optic`, cron jobs can also be managed through the :ref:`gloss-admin-tool`.

Once a cron job is created, you can modify many of its properties (such as its name and description, or
the Storm associated with the job). However, you cannot modify other aspects of the job, such as its schedule.
To change those conditions, you must disable (or delete) and re-create the cron job.

.. _auto-cron-vars:

Variables
~~~~~~~~~

Every cron job has an associated Storm variable ``$auto`` that is automatically populated when the job runs.
The ``$auto`` variable is a dictionary which contains the following keys:

  ``$auto.iden``
    The identifier of the cron job.

  ``$auto.type``
    The type of automation. For a cron job this value will be ``cron``.

These job-specific variables / dictionary entries can be referenced by the Storm code executed by the cron job.

See :ref:`storm-adv-vars` for information on the use of variables in Storm.


.. _auto-cron-examples:

Examples
~~~~~~~~

The examples below illustrate using the Storm :ref:`storm-cron` commands (``cron.at``, ``cron.add``) to create
new cron jobs.

`Add a one-time (non-recurring) cron job that runs at 0200 UTC to lift all articles (media:news nodes) and delete the deprecated :author property:`

.. storm-pre:: [ (media:news=* :author='ron the cat' :title='my article') (media:news=* :title='your article') ]
.. storm-pre:: media:news:author [ -:author ]

.. storm-cli:: cron.at --hour 2 { media:news:author [ -:author ] }

We can view the details of this cron job using the ``cron.list`` command:

.. storm-cli:: cron.list

The output of ``cron.list`` contains the following columns:

- **user** - the username used to create the job / that the job runs as.
- **iden** - the first eight characters of the cron job's identifier (iden).
- **view** - the first eight characters of the iden of the view the job executes in. For "orphaned" cron
  jobs, this will be the job's last view (before it was orphaned).
- **en?** - whether the job is currently enabled or disabled ( Y/N ).
- **rpt?** - whether the job is scheduled to repeat ( Y/N ).
- **now?** - whether the job is currently executing ( Y/N ).
- **err?** - whether the last job execution encountered an error ( X or empty ).
- **# start** - the number of times the job has started / executed (since the last restart of Syanpse).
- **last start** - the date and time the job last started (or attempted to start).
- **last end** - the date and time the job last finished (or exited).
- **query** - the Storm query executed by the cron job.

.. TIP::
  
  Detailed information about individual cron jobs can be retrieved with the :ref:`storm-cron-stat` command.

We can also view limited information about the cron job by lifting its ``syn:cron`` node:

.. storm-cli:: syn:cron

.. TIP::
  
  You can optionally set the ``:name`` and ``:doc`` properties of the ``syn:cron`` node using Storm's
  edit (data modification) syntax to :ref:`prop-add-mod`.


`Add a cron job that runs every hour and downloads the latest MISP data using the misp.sync command:`

::
  
  cron.add --hour +1 | misp.sync

.. TIP::
  
  The ``misp.sync`` command is added by the `Synapse-MISP`_ Power-Up.


`Add a cron job that runs every Tuesday, Thursday, and Saturday at 20:00 UTC to check for any files (file:bytes nodes) that query "known bad" FQDNs (tagged #cno.mal) where the file has NOT been tagged as malicious, and flag the file for review (i.e., tag it #int.review.malware):`


.. storm-pre:: cron.add --day Tue,Thu,Sat --hour 20 { inet:fqdn#cno.mal -> inet:dns:request -> file:bytes -#cno.mal [ +#int.review.malware ] }
::
  
  cron.add --day Tue,Thu,Sat --hour 20 { inet:fqdn#cno.mal -> inet:dns:request -> file:bytes -#cno.mal [ +#int.review.malware ] }


.. _auto-triggers:

Triggers
++++++++

Triggers are "event-driven" automation. As their name implies, they trigger ("fire") their associated Storm
when specific events occur in Synapse's data store. Triggers can fire on the following events:

- Adding a node (``node:add``)
- Deleting a node (``node:del``)
- Setting (or modifying) a property (``prop:set``)
- Adding a tag to a node (``tag:add``)
- Deleting a tag from a node (``tag:del``)
- Adding a light edge (``edge:add``)
- Deleting a light edge (``edge:del``).

Each event requires an object (a form, property, tag, or edge) to act upon - that is, if you write a trigger to
fire on a ``node:add`` event, you must specify the type of node (form) associated with the event. For ``tag:*``
and ``edge:*`` triggers, you have the option to limit the trigger to tags or edges associated with specific
forms, or have the trigger apply to any / all forms.

.. NOTE::
  
  The node(s) that cause a trigger to fire are considered **inbound** to the Storm code executed by the
  trigger.


.. _auto-trigger-config:

Configuration and Management
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- **Storage.** Triggers are stored within a **view** and execute within the view where they are stored. If the
  view that a trigger resides in is deleted, **the trigger is also deleted**. Triggers can be moved to another
  view using the ``$trigger.move()`` method (:ref:`stormprims-trigger-move`).
  
  Because triggers are stored within individual views, when **viewing** triggers (e.g., with the :ref:`storm-trigger-list`
  command), Synapse returns only those triggers within the current view.

- **Execution.** Triggers "fire" when a change occurs within Synapse - that is, when a **write** operation occurs.
  Triggers reside (and execute) within a **view**, so they fire on changes to the view's writable (topmost) layer.
  A trigger will **not** fire on changes made in an underlying layer (i.e., of a parent view).
  
  Similarly, a trigger that resides in a **parent** view will **not** fire on changes made in a fork of that view.
  However, when data from the forked view is merged into the parent view, merging (writing) the data will cause
  any relevant triggers to fire.
  
  Triggers fire immediately when their associated event occurs. However, they **only** execute when that event occurs.
  This means that if a trigger depends on a resource (process, service, etc.) that is not available when it fires,
  the trigger will simply fail; it will not "try again" (whether the trigger fails silently or by logging an error
  will depend on the Storm and / or any additional resources used (such as `Power-Ups`)).
  
  Similarly, triggers do not operate "retroactively" on existing data. If you write a new trigger to fire when
  the tag ``my.tag`` is applied to a ``hash:md5`` node, the trigger will have no effect on existing ``hash:md5``
  nodes that already have the tag.

- **Permissions.** Triggers execute with the privileges of a designated user (typically the user who creates the
  trigger). We strongly encourage the use of least privilege; the trigger's account should have the permissions
  required to execute the associated Storm, but no more. One option is for organizations to create a dedicated
  account for use with automation in Synapse.
  
  The owner (user) of a trigger can be modified using the Storm :ref:`stormlibs-lib-trigger-get` library and
  :ref:`stormprims-trigger-f527` primitive. For example:
  
  ::
    
    $mytrigger=$lib.trigger.get(<trigger_iden>) $mytrigger.set(user, <new_user_iden>)
  
  Triggers execute with the privileges of a specific user, but they execute based on a specific changes to data in
  Synapse. This means that a lower-privileged user could make a change (such as creating a node) that causes a
  higher-privileged trigger to execute and perform actions that the user would not be able to do themselves.
  
  Users (and roles) cannot create or manage triggers by default. The various ``trigger.*`` permissions must be granted
  to users or roles that should be allowed to work with triggers in your environment.
  
  See the `Cortex permissions`_ section of the `Synapse Admin Guide`_ for details on the ``trigger.*`` permissions
  and associated gates.
  
  .. NOTE::
    
    Where a user has **admin** privileges, all permissions checks are bypassed. This means (for example) that
    users can create and manage triggers in views that they fork.


- **Managing Triggers.** Triggers can be createtd, viewed, and managed using the various Storm :ref:`storm-trigger`
  commands, the :ref:`stormprims-trigger-f527` methods, or the :ref:`stormlibs-lib-trigger` libraries.
  
  When a trigger is created, Synapse also generates a ``syn:trigger`` runtime node ("runt node") with some
  details about the trigger available as properties on the node. While runt nodes are typically read-only, ``syn:trigger``
  nodes include ``:name`` and ``:doc`` secondary properties that can be set and modified via Storm (or configured via
  :ref:`gloss-optic`). This allows you to manage triggers by giving them meaningful names and descriptions. Changes
  to these properties will persist even after a Cortex restart.
  
  Runt nodes can be lifted, viewed, filtered, etc. just like other nodes in Synapse, which allows you to perform
  limited introspection_ of triggers using Storm.


.. _auto-trigger-use:

Use Cases
~~~~~~~~~

Triggers are "event driven" and execute their associated Storm **immediately** when their associated event
(change) occurs. As such, triggers are most appropriate for automating tasks that should occur right away (e.g.,
based on efficiency or importance). Example use cases for triggers include:

- **Performing enrichment.** There are circumstances where you "always" want additional information about a
  an object (node) within Synapse. For example, you may **always** want to look up Autonomous System (AS),
  geolocation, or network whois data whenever a unicast IPv4 (``inet:ipv4`` node) is added to Synapse.
  You can use a trigger to enrich the ``inet:ipv4`` using the appropriate `Power-Ups`_ as soon as the IPv4
  is created (e.g., by firing on a ``node:add`` event).
  
  Similarly, when a node is assessed to be malicious (e.g., associated with a threat cluster or malware
  family, and tagged appropriately), you may wish to immediately collect additional information about that
  node. A trigger that fires on a ``tag:add`` event could be used to call multiple `Power-Ups`_ using a more
  extensive "enrichment" query.

- **Encoding and applying assessments.** You can use storm to encode the logic you use to apply a tag. As
  a simplified example, assume you have identified an IPv4 address as a DNS sinkhole. When a DNS A node
  (``inet:dns:a``) is created where the associated IPv4 (``:ipv4`` property) is the IP of the sinkhole
  (a ``prop:set`` event), a trigger can automatically tag the associated FQDN as sinkholed. If you want
  an analyst to confirm the assessment (vs. applying it in a fully automated fashion), you can apply a
  "review" tag instead.
  
  You can similarly encode more detailed logic to support retrohunting, threat clustering, or other workflows.

- **Automating repetetive tasks.** Any process that analysts identify as repetetive may benefit from automation.
  For example, analysts may identify cases where, when they tag a particular node, they always want to tag a set
  of "related" nodes. A common use cases is when analysts tag a ``file:bytes`` node (as malicious, or associated
  with a particular threat group) they also want to tag the file's associated hash values (``hash:md5``, etc.).
  Similarlry, if a ``file:bytes`` node queries a "known bad" FQDN (via an ``inet:dns:request`` node), analysts
  also want to apply the tag from the FQDN to both the DNS request and the file. Using a trigger (on a ``tag:add``
  event) saves manual work by the analyst and ensures the additional tags are applied consistently.


.. _auto-trigger-syntax:

Syntax
~~~~~~

Triggers are created, modified, viewed, enabled, disabled, and deleted using the Storm :ref:`storm-trigger`
commands. In :ref:`gloss-optic`, cron jobs can also be managed through the :ref:`gloss-admin-tool`.

Once a trigger is created, you can modify many of its properties (such as its name and description, or
the Storm associated with the trigger). However, you cannot modify the conditions that cause the trigger to
fire. To change those conditions, you must disable (or delete) and re-create the trigger.


.. _auto-trigger-vars:

Variables
~~~~~~~~~

Every trigger has an associated Storm variable ``$auto`` that is automatically populated when the job runs.
The ``$auto`` variable is a dictionary which contains the following keys:

  ``$auto.iden``
    The identifier of the Trigger.

  ``$auto.type``
    The type of automation. For a trigger this value will be ``trigger``.

  ``$auto.opts``
    Dictionary containing trigger-specific runtime information. This includes the following keys:

        ``$auto.opts.form``
            The form of the triggering node.

        ``$auto.opts.propfull``
            The full name of the property that was set on the node. Only present on ``prop:set`` triggers.

        ``$auto.opts.propname``
            The relative name of the property that was set on the node. Does not include a leading ``:``.
            Only present on ``prop:set`` triggers.

        ``$auto.opts.tag``
            The tag which caused the trigger to fire. Only present on ``tag:add`` and ``tag:del`` triggers.

        ``$auto.opts.valu``
            The value of the triggering node.

        ``$auto.opts.verb``
            The name of the light edge. Only present on ``edge:add`` and ``edge:del`` triggers.

        ``$auto.opts.n2iden``
            The iden of the node on the other end of the edge. Only present on ``edge:add`` and ``edge:del`` triggers.

These trigger-specific variables / dictionary entries can be referenced by the Storm code executed by the trigger.

See :ref:`storm-adv-vars` for information on the use of variables in Storm.


.. _auto-trigger-examples:

Examples
~~~~~~~~












- By default, triggers execute **inline**. When a process (typically a Storm query) causes a trigger to
  fire, the Storm associated with the trigger will run **immediately and in full**. Conceptually, it is
  as though all of the trigger’s Storm code and any additional Storm that it calls (such as a macro) are
  inserted into the middle of the original Storm query that fired the trigger, and executed as part of
  that query.
  
  .. WARNING::
    
    This inline execution can impact your query's performance, depending on the Storm executed by the
    trigger and the number of nodes causing the trigger to fire. The ``--async`` option can be used when
    creating a trigger to specify that the trigger should run in the background as opposed to inline.
    This will cause the trigger event to be stored in a persistent queue, which will then be consumed
    automatically by the Cortex.
    
    As an example, you are reviewing a whitepaper on a new threat group that includes 800 indicators
    of compromise reportedly associated with the group. You tag all of the indicators, which fires a
    trigger to "enrich" those indicators from multiple third-party APIs and results in the creation of
    dozens of new nodes for each indicator enriched. This tag-and-enrich process is executed inline for
    **each** of the 800 indicators, which can slow or appear to "block" the original query you ran in
    order to apply the tags.
    
    If the trigger is created as an ``async`` trigger to run in the background, the query to apply the
    tags will finish quickly. This allows you to continue working while the associated enrichment
    completes in the background.


- In some cases proper trigger execution may depend on the timing and order of events with respect to
  creating nodes, setting properties, and so on. For example, you may write a trigger based on a
  ``node:add`` action that fails to perform as expected because you actually need the trigger to fire
  on a ``prop:set`` operation. The detailed technical aspects of Synapse write operations are beyond the
  scope of this discussion; as always it is good practice to test triggers (or other automation) before 
  putting them into production.







Syntax
~~~~~~

Triggers are created, modified, viewed, enabled, disabled, and deleted using the Storm ``trigger.*`` commands.
See the :ref:`storm-trigger` command in the :ref:`storm-ref-cmd` document for details.

In :ref:`gloss-optic`, triggers can also be managed through either the :ref:`gloss-admin-tool` or the
:ref:`gloss-workspaces-tool`.

.. NOTE::
  
  Once a trigger is created, you can modify many of its properties (such as its name and description, or
  the Storm associated with the trigger). However, you cannot modify the trigger conditions (e.g., the type of
  event that fires the trigger, or the form a trigger operates on). To change those conditions, you must
  delete and re-create the trigger.


Examples
~~~~~~~~

In the examples below, we show the command to create (add) the specified trigger.

For illustrative purposes, in the **first** example the newly created trigger is displayed using the
``trigger.list`` command and then by lifting the associated ``syn:trigger`` runtime ("runt") node.

- Add a trigger that fires when an ``inet:whois:email`` node is created. If the email address is associated
  with a privacy-protected registration service (e.g., the email address is tagged ``whois.private``),
  then also tag the ``inet:whois:email`` node.


.. storm-cli:: trigger.add --name "tag privacy protected inet:whois:email" node:add --form inet:whois:email --query { +{ -> inet:email +#whois.private } [ +#whois.private ] }

Newly created trigger via ``trigger.list``:
  
.. storm-cli:: trigger.list

The output of ``trigger.list`` contains the following columns:

- The username used to create the trigger.
- The trigger's identifier (iden).
- Whether the trigger is currently enabled or disabled.
- Whether the trigger will run asynchronously / in the background.
- The condition that causes the trigger to fire.
- The object that the condition operates on, if any.
- The tag or tag expression used by the condition (for ``tag:add`` or ``tag:del`` conditions only).
- The query to be executed when the trigger fires.

Newly created trigger as a ``syn:trigger`` node:
  
.. storm-cli:: syn:trigger


- Add a trigger that fires when the ``:exe`` property of an ``inet:dns:request`` node is set. Check to see
  whether the queried FQDN is malicious; if so, tag the associated ``file:bytes`` node for analyst review.
  
.. storm-cli:: trigger.add --name "tag file:bytes for review" prop:set --prop inet:dns:request:exe --query { +{ :query:name -> inet:fqdn +#malicious } :exe -> file:bytes [ +#review ] }


- Add a trigger that fires when the tag ``cno.ttp.phish.payload`` is applied to a ``file:bytes`` node (indicating
  that a file was an attachment to a phishing email). Use the trigger to **also** apply the tag ``attack.t1566.001``
  (representing the MITRE ATT&CK technique "Spearphishing Attachment").

.. storm-cli:: trigger.add --name "tag phish attachment with #attack.t1566.001" tag:add --form file:bytes --tag cno.ttp.phish.payload --query { [ +#attack.t1566.001 ] }


- Add a trigger that fires when the tag ``osint`` (indicating that the node was listed as a malicious indicator
  in public reporting) is applied to any node. The trigger should call (execute) a macro called ``enrich``.
  The macro contains a Storm query that uses a switch case to call the appropriate Storm commands based on the
  tagged node’s form (e.g., perform different enrichment / call different third-party services based on whether
  the node is an FQDN, an IPv4, an email address, a URL, etc.).
  
.. storm-pre:: $pkg=$lib.dict(name='docs', version='0.0.1', commands=($lib.dict(name=whois, storm=${} ),)) $lib.print($pkg) $lib.pkg.add($pkg)
.. storm-pre:: $pkg=$lib.dict(name='docs', version='0.0.1', commands=($lib.dict(name=malware, storm=${} ),)) $lib.print($pkg) $lib.pkg.add($pkg)
.. storm-pre:: $pkg=$lib.dict(name='docs', version='0.0.1', commands=($lib.dict(name=revwhois, storm=${} ),)) $lib.print($pkg) $lib.pkg.add($pkg)
.. storm-pre:: macro.set enrich ${ switch $node.form() {/* You can put comments in macros!!! */ "inet:fqdn": { | whois | pdns | malware } "inet:ipv4": { | pdns } "inet:email": { | revwhois } *: { } } }
  
.. storm-cli:: trigger.add --name "enrich osint" tag:add --tag osint --query { | macro.exec enrich }




.. _auto-macros:

Macros
------

A macro is simply a stored Storm query / set of Storm code that can be executed on demand.

Strictly speaking, macros are not automation - they do not execute on their own. However, macros are often
used with (called by) triggers or cron jobs.

Macros differ from triggers and cron in some important ways:

- **Permissions.** No special permissions are required to work with macros. Any user can create or call
  a macro.

- **Execution.** Macros execute with the permissions **of the calling user.** A macro can only perform
  actions that the calling user has permissions to perform. If a user runs a macro that whose actions
  exceed the user's permissions, the macro will fail with an ``AuthDeny`` error.

- **Introspection.** Synapse does not create runtime nodes ("runt nodes") for macros.
  
- **Scope.** Where triggers and cron jobs are specific to a :ref:`gloss-view`, macros are specific to a
  given Cortex. Macros can be viewed, modified, and executed from any view.


Example Use Cases
+++++++++++++++++

Macros are a convenient way to save and run frequently used Storm without having to create or type that
Storm each time. The Storm can be as simple or advanced as you like.

- **Organizational use.** Macros can be developed for use across entire teams or organizations to support
  common tasks or workflows such as enrichment or threat hunting. Using a macro makes it easier to perform
  the task (by calling it with a single Storm command) and also ensures that the task is performed
  consistently (i.e., in the same way each time) by each user.

- **Personal use.** Users can create macros to store frequently-used or lengthy Storm queries specific to
  their personal workflow that can be executed easily on demand.

- **Automation.** For triggers or cron jobs that execute longer Storm queries, saving the Storm in a macro
  may make it easier to set, view, edit, and manage vs. storing the Storm directly as part of the trigger
  or cron job.

- **Flexibility.** Because macros are composed in Storm and executed via a Storm command, they can be
  executed any way Storm can be executed (e.g., on demand or called as part of a trigger or cron job). Macros
  are ideal for Storm that performs a task or set of tasks that you may want to execute in a variety of
  ways.


Usage Notes
+++++++++++

- Macros are specific to an individual Synapse Cortex; they are not limited to an individual
  :ref:`gloss-view`. Any macros that exist in a Cortex are visible to all users of that Cortex.

- Any user can create or run a macro. You do not need to explicitly grant any permissions.

- Macros are differentiated by name, and cannot be renamed once created.

- The user who creates a macro is the owner / admin of the macro. Other users can read and execute
  the macro (within the limitations of their permissions), but cannot modify or delete it.

- Macros execute with the permissions **of the calling user.**

  - While any user can execute any macro, if the macro takes some action that the calling user does not
    have permission to perform, the macro will fail with an ``AuthDeny`` error.
  
  - If a macro is called by a trigger or cron job, the macro will execute with the permissions of 
    **the author of the trigger or cron job.**

- Macros commonly take nodes as input. Similarly, a macro may output nodes based on the Storm it executes.
  For both of these conditions, Storm's "pipeline" behavior applies. A macro will error if it receives
  nodes that cannot be processed by the associated Storm code; similarly, if you execute additional
  Storm after the macro runs, that Storm must be appropriate for any nodes that exit the macro.


Syntax
++++++

Macros are created, modified, viewed, and deleted using the Storm ``macro.*``  commands. See the
:ref:`storm-macro` command in the :ref:`storm-ref-cmd` document for details.

In :ref:`gloss-optic`, macros can also be managed through the :ref:`gloss-storm-editor`.


Examples
++++++++

- Add a macro named ``sinkhole.check`` that lifts all IPv4 addresses tagged as sinkholes
  (``#cno.infra.dns.sinkhole``) and submits those nodes to a Storm command that calls a third-party
  passive DNS service to retrieve any FQDNs currently resolving to the sinkhole IP. (**Note:** Synapse
  does not include a passive DNS service in its open source distribution; the macro assumes such a
  service has been implemented.)

.. storm-pre:: $pkg=$lib.dict(name='docs', version='0.0.1', commands=($lib.dict(name=pdns, storm=${} ),)) $lib.print($pkg) $lib.pkg.add($pkg)
.. storm-cli:: macro.set sinkhole.check ${ inet:ipv4#cno.infra.dns.sinkhole | pdns }


- Add a macro named ``check.c2`` that takes an inbound set of ``file:bytes`` nodes and returns any FQDNs
  that the files query and any IPv4 addresses the files connect to. Use a filter in the macro to ensure that
  the macro code only attempts to process inbound ``file:bytes`` nodes.

.. storm-cli:: macro.set check.c2 ${ +file:bytes | tee { -> inet:dns:request :query:name -> inet:fqdn | uniq } { -> inet:flow:src:exe :dst:ipv4 -> inet:ipv4 | uniq } }

- Add a macro named ``enrich`` that takes any node as input and uses a ``switch`` statement to call Storm
  commands for third-party services able to enrich a given form (line breaks and indentations used for readability).
  (**Note:** Synapse does not include third-party services / connectors in its open source distribution;
  the macro assumes such services have been implemented.)

.. storm-pre:: $pkg=$lib.dict(name='docs', version='0.0.1', commands=($lib.dict(name=whois, storm=${} ),)) $lib.print($pkg) $lib.pkg.add($pkg)
.. storm-pre:: $pkg=$lib.dict(name='docs', version='0.0.1', commands=($lib.dict(name=malware, storm=${} ),)) $lib.print($pkg) $lib.pkg.add($pkg)
.. storm-pre:: $pkg=$lib.dict(name='docs', version='0.0.1', commands=($lib.dict(name=revwhois, storm=${} ),)) $lib.print($pkg) $lib.pkg.add($pkg)
.. storm-multiline:: ENRICH="macro.set enrich ${ switch $node.form() {\n\n    /* You can put comments in macros!!! */\n\n    \"inet:fqdn\": { | whois | pdns | malware }\n    \"inet:ipv4\": { | pdns }\n    \"inet:email\": { | revwhois }\n    *: { }\n} }"
.. storm-cli:: MULTILINE=ENRICH


.. _auto-dmon:

Dmons
-----

A :ref:`gloss-dmon` is a long-running or recurring query or process that runs continuously in the background, similar to a traditional Linux or Unix daemon.

Variables
+++++++++

Dmons will have the storm variable ``$auto`` populated when they run. The ``$auto`` variable is a dictionary which
contains the following keys:

  ``$auto.iden``
    The identifier of the Dmon.

  ``$auto.type``
    The type of automation. For a Dmon this value will be ``dmon``.

.. NOTE::
  If the variable ``$auto`` was captured during the creation of the Dmon, the variable will **not** be mapped in.


Syntax
++++++

Users can interact with dmons using the Storm ``dmon.*``  commands (see the :ref:`storm-dmon` command in the
:ref:`storm-ref-cmd` document for details) and the :ref:`stormlibs-lib-dmon` Storm libraries.

.. _Synapse Admin Guide: https://synapse.docs.vertex.link/en/latest/synapse/adminguide.html
.. _Cortex permissions: https://synapse.docs.vertex.link/en/latest/synapse/adminguide.html#cortex-permissions
.. _introspection: https://synapse.docs.vertex.link/en/latest/synapse/userguides/storm_ref_model_introspect.html#data-model
.. _Synapse Maxmind: https://synapse.docs.vertex.link/projects/maxmind/en/latest/
.. _Synapse-MISP: https://synapse.docs.vertex.link/projects/rapid-powerups/en/latest/storm-packages/synapse-misp/index.html
.. _Power-Ups: https://synapse.docs.vertex.link/en/latest/synapse/power_ups.html
